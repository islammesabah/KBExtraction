<!-- This document is automatically generated by LLM -not updated yet -->

# TrustifAI

**TrustifAI** is a modular framework for extracting, structuring, and analyzing requirements and qualities for AI systems from unstructured documents. It leverages state-of-the-art language models, prompt engineering, and knowledge graph technologies to enable transparent, explainable, and auditable AI requirement management.

<p align="center">
<img src="./Figures_Resources/DesignDiagram2.jpeg" alt="Design Diagram" width="70%">
</p>

---

## Features

- **Automated Extraction**: Extracts requirements and qualities from PDF and text documents using advanced NLP and LLMs.
- **Chunking & Sentence Decomposition**: Supports both sentence-level and chunk-level document processing for flexible information granularity.
- **Knowledge Graph Structuring**: Structures extracted information into a Neo4j graph database for advanced querying and visualization.
- **Interactive Terminal Interface**: Provides a user-friendly terminal interface for managing data sources, extraction types, and graph operations.
- **User Feedback Logging**: Logs user corrections and decisions to continuously improve extraction and structuring quality.
- **Configurable Pipeline**: Easily configure data sources, extraction types, and retrieval approaches via `config.ini`.

---

## Project Structure

```
.
├── trustifai.py                  # Main entry point for the system
├── trustifai_config.py           # Configuration-based entry point
├── terminal_interface.py         # Terminal UI for user interaction
├── Requirement_Extraction/       # Extraction and decomposition modules
├── Graph_Structuring/            # Graph creation and Neo4j integration
├── Data/                         # Source documents (PDFs, text)
├── Log/                          # User feedback and system logs
├── Cluster/                      # Containerization and deployment scripts
├── Notebooks/                    # Jupyter notebooks for experiments and fine-tuning
├── config.ini                    # System configuration file
├── README.md                     # Project documentation
└── ...
```

---

## Quick Start

### 1. Install Dependencies

```sh
pip install -r requirements.txt
```

### 2. Configure the System

Edit `config.ini` to set data sources, extraction types, and Neo4j connection details.

### 3. Run the System

```sh
python trustifai.py
```
or, for configuration-driven runs:
```sh
python trustifai_config.py
```

### 4. Use the Terminal Interface

Follow the prompts to select data sources, extraction types (sentence/chunk), and manage the knowledge graph.

---

## Core Modules

- **Requirement Extraction**:  
  - `txt_sentences_extraction.py`, `pdf_sentences_extraction.py`, `pdf_chunks.py`  
  - Extracts sentences/chunks from documents.
- **Decomposition**:  
  - `sentence_decompose.py`, `chunk_decompose.py`  
  - Breaks down sentences/chunks into structured requirements or qualities.
- **Graph Structuring**:  
  - `relationship_extraction.py`, `neo4j_structure.py`  
  - Converts extracted information into graph relations and uploads to Neo4j.
- **Logging**:  
  - `logs_dataframe.py`  
  - Records user feedback and system actions.

---

## Notebooks

The `Notebooks/` directory contains Jupyter notebooks for:
- Fine-tuning LLMs (e.g., Mistral-7B)
- Experimenting with prompt engineering
- Evaluating extraction and graph structuring approaches

---

## Acknowledgements

- [LangChain](https://github.com/langchain-ai/langchain)
- [Neo4j](https://neo4j.com/)
- [HuggingFace Transformers](https://huggingface.co/transformers/)
